{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00689488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps as cm\n",
    "\n",
    "from f3 import init_event_model, load_weights_ckpt\n",
    "from f3.utils import (setup_torch, ev_to_frames, plot_patched_features,\n",
    "                      smooth_time_weighted_rgb_encoding, BaseExtractor)\n",
    "from f3.tasks.depth.utils import init_depth_model, load_depth_weights, get_disparity_image\n",
    "from f3.tasks.optical_flow.utils import init_flow_model, load_flow_weights, flow_viz_np\n",
    "from f3.tasks.segmentation.utils import init_segmentation_model, load_segmentation_weights, cityscapes_palette\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format=\"%(asctime)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "setup_torch(cudnn_benchmark=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0a9cb7",
   "metadata": {},
   "source": [
    "### Download Pretrained Models and a Minimal M3ED Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d248b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pretrained F3 model weights\n",
    "!bash scripts/download/download_models.sh pretrained_models/f3 f3\n",
    "!bash scripts/download/download_models.sh pretrained_models/seg seg\n",
    "!bash scripts/download/download_models.sh pretrained_models/depth depth\n",
    "!bash scripts/download/download_models.sh pretrained_models/flow flow\n",
    "\n",
    "# Download a small M3ED sequence and generate the timestamps file\n",
    "!python3 scripts/download/download_m3ed.py --vehicle car\\\n",
    "                                           --environment urban\\\n",
    "                                           --sequence car_urban_day_penno_small_loop\\\n",
    "                                           --output_dir data\\\n",
    "                                           --to_download data\n",
    "!python3 scripts/generate_ts.py --data_h5 data/car_urban_day_penno_small_loop/car_urban_day_penno_small_loop_data.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4496cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Path where Models are downloaded ################\n",
    "BASE_F3_MODEL_PATH = \"pretrained_models/f3/\"\n",
    "BASE_SEG_MODEL_PATH = \"pretrained_models/seg/\"\n",
    "BASE_DEPTH_MODEL_PATH = \"pretrained_models/depth/\"\n",
    "BASE_FLOW_MODEL_PATH = \"pretrained_models/flow/\"\n",
    "\n",
    "################ Model Names to Load ################\n",
    "F3_MODEL_NAME = \"patchff_fullcardaym3ed_small_20ms.pth\"\n",
    "F3_CONFIG_NAME = \"confs/ff/modeloptions/1280x720x20_patchff_ds1_small.yml\"\n",
    "SEG_MODEL_NAME = \"segformer_b3_fullm3ed_800x600x20\"\n",
    "DEPTH_MODEL_NAME = \"dav2b_fullm3ed_pseudo_518x518x20\"\n",
    "FLOW_MODEL_NAME = \"optflow_trainm3ed_20msff_pyr5_28k\"\n",
    "\n",
    "################ Path to a M3ED Sequence ################\n",
    "H5PATH = \"data/car_urban_day_penno_small_loop/car_urban_day_penno_small_loop_data.h5\"\n",
    "TSPATH = \"data/car_urban_day_penno_small_loop/50khz_car_urban_day_penno_small_loop_data.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdde4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = BaseExtractor(H5PATH, TSPATH, w=1280, h=720, time_ctx=20000,\n",
    "                          time_pred=20000, bucket=1000, max_numevents_ctx=800000,\n",
    "                          randomize_ctx=False, camera=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392cbc58",
   "metadata": {},
   "source": [
    "## Initializing and Loading Pretrained Models\n",
    "\n",
    "### Loading a pretrained F<sup>3</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45828ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventff_model = init_event_model(F3_CONFIG_NAME, return_feat=True, return_logits=True).cuda()\n",
    "eventff_model = torch.compile(\n",
    "    eventff_model,\n",
    "    fullgraph=False,\n",
    "    backend=\"inductor\",\n",
    "    options={\n",
    "        \"epilogue_fusion\": True,\n",
    "        \"max_autotune\": True,\n",
    "    },\n",
    ")\n",
    "epoch, loss, acc = load_weights_ckpt(eventff_model, Path(BASE_F3_MODEL_PATH) / F3_MODEL_NAME)\n",
    "eventff_model.eval()\n",
    "logger.info(f\"Loaded F3 model ckpt from {F3_MODEL_NAME} at epoch {epoch} with loss {loss} and acc {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4bab05",
   "metadata": {},
   "source": [
    "### Loading a pretrained F<sup>3</sup> - SegFormer B3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186c9272",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model = init_segmentation_model(Path(BASE_SEG_MODEL_PATH) / SEG_MODEL_NAME / \"segmentation_config.yml\").cuda()\n",
    "seg_model.eventff = torch.compile(seg_model.eventff, fullgraph=False)\n",
    "epoch, loss, acc, miou = load_segmentation_weights(seg_model, Path(BASE_SEG_MODEL_PATH) / SEG_MODEL_NAME / \"best_miou.pth\")\n",
    "logger.info(f\"Loaded Segmentation ckpt from {SEG_MODEL_NAME} at \" +\n",
    "            f\"Epoch: {epoch}, Loss: {loss}, Acc: {acc}, MIoU: {miou}\")\n",
    "seg_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3ea137",
   "metadata": {},
   "source": [
    "### Loading a pretrained F<sup>3</sup> - DepthAnything V2 Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f54c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_model = init_depth_model(Path(BASE_DEPTH_MODEL_PATH) / DEPTH_MODEL_NAME / \"depth_config.yml\").cuda()\n",
    "depth_model.eventff = torch.compile(depth_model.eventff, fullgraph=False)\n",
    "epoch, results = load_depth_weights(depth_model, Path(BASE_DEPTH_MODEL_PATH) / DEPTH_MODEL_NAME / \"best.pth\")\n",
    "logger.info(f\"Loaded Monocular Depth ckpt from {DEPTH_MODEL_NAME} at \" +\n",
    "            f\"Epoch: {epoch}, Results: {results}\")\n",
    "depth_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b10b138",
   "metadata": {},
   "source": [
    "### Loading a pretrained F<sup>3</sup> - Flow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb2f1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optflow_model = init_flow_model(Path(BASE_FLOW_MODEL_PATH) / FLOW_MODEL_NAME / \"flow_config.yaml\").cuda()\n",
    "optflow_model.eventff = torch.compile(optflow_model.eventff, fullgraph=False)\n",
    "optflow_model.flowhead = torch.compile(optflow_model.flowhead, fullgraph=False)\n",
    "epoch, loss = load_flow_weights(optflow_model, Path(BASE_FLOW_MODEL_PATH) / FLOW_MODEL_NAME / \"last.pth\")\n",
    "logger.info(f\"Loaded Optical Flow ckpt from {FLOW_MODEL_NAME} at \" +\n",
    "            f\"Epoch: {epoch}, Loss: {loss}\")\n",
    "optflow_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4ababa",
   "metadata": {},
   "source": [
    "### Run all models for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012b18ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_IDX = 700\n",
    "\n",
    "t0 = extractor.hdf5_file[\"ovc/ts\"][IMG_IDX]\n",
    "img = extractor.hdf5_file[\"ovc/rgb/data\"][IMG_IDX]\n",
    "\n",
    "# get events in fixed time window\n",
    "ctx, totcnt = extractor.get_ctx_fixedtime(t0)    \n",
    "ctx, totcnt = ctx.cuda(), torch.tensor([totcnt]).cuda()\n",
    "\n",
    "# make event frame for visualization\n",
    "events_frame = ev_to_frames(ctx, totcnt, 1280, 720)[0].cpu().numpy().T\n",
    "\n",
    "cmap = cm.get_cmap(\"magma\")\n",
    "\n",
    "# Run all models\n",
    "with torch.no_grad():\n",
    "    # F3 forward pass\n",
    "    logits, feat = eventff_model(ctx, totcnt)\n",
    "    \n",
    "    # Segmentation forward pass\n",
    "    seg_pred, _ = seg_model(ctx, totcnt)\n",
    "    seg_pred = seg_pred.argmax(1).cpu().numpy()\n",
    "\n",
    "    # Depth forward pass\n",
    "    depth_pred, _ = depth_model.infer_image(ctx, totcnt)\n",
    "\n",
    "    # Optical Flow forward pass\n",
    "    flow_pred, _ = optflow_model(ctx, totcnt)\n",
    "    flow_pred = flow_pred.permute(0, 2, 3, 1).cpu().numpy()\n",
    "\n",
    "pca, _ = plot_patched_features(feat[0], plot=False)\n",
    "logits_rgb = smooth_time_weighted_rgb_encoding((torch.sigmoid(logits) > 0.5).cpu().numpy())[0]\n",
    "seg_img = cityscapes_palette(seg_model.num_labels)[seg_pred[0]].astype(np.uint8)\n",
    "depth_img = get_disparity_image(depth_pred, torch.ones_like(depth_pred, dtype=torch.bool), cmap)\n",
    "flow_img = flow_viz_np(flow_pred[0], norm=True) * (events_frame == 255)[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca3fdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add optical flow to the visualization\n",
    "fig, axes = plt.subplots(2, 4, figsize=(24, 8))\n",
    "\n",
    "# Original RGB image\n",
    "axes[0, 0].imshow(img[..., ::-1])\n",
    "axes[0, 0].set_title('Original RGB Image', fontsize=20, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Events frame\n",
    "axes[0, 1].imshow(events_frame, cmap='hot')\n",
    "axes[0, 1].set_title('Events Frame', fontsize=20, fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# PCA features\n",
    "axes[0, 2].imshow(pca.transpose(1, 0, 2))\n",
    "axes[0, 2].set_title('PCA Features', fontsize=20, fontweight='bold')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Logits RGB\n",
    "axes[0, 3].imshow(logits_rgb.transpose(1, 0, 2))\n",
    "axes[0, 3].set_title('Logits RGB', fontsize=20, fontweight='bold')\n",
    "axes[0, 3].axis('off')\n",
    "\n",
    "# Segmentation prediction\n",
    "axes[1, 0].imshow(seg_img[..., ::-1])\n",
    "axes[1, 0].set_title('Segmentation Prediction', fontsize=20, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "# Depth image\n",
    "axes[1, 1].imshow(depth_img)\n",
    "axes[1, 1].set_title('Depth Prediction', fontsize=20, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "# Optical flow\n",
    "axes[1, 2].imshow(flow_img[..., ::-1])\n",
    "axes[1, 2].set_title('Optical Flow', fontsize=20, fontweight='bold')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "# Remove empty subplot\n",
    "axes[1, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
